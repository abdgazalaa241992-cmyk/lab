{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdgazalaa241992-cmyk/lab/blob/main/IUG_Practical_Assignment_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU1yrb3eD7XJ"
      },
      "source": [
        "# Given the dataset below, perform the required task for each question and display the output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d2OHNBgmBki",
        "outputId": "939a278a-226e-497b-8c73-be535c39db01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['A', 'B'], ['A'], ['B'], ['A', 'B'], []]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transactions = [\n",
        "    ['A', 'B'],   # T1\n",
        "    ['A'],        # T2\n",
        "    ['B'],        # T3\n",
        "    ['A', 'B'],   # T4\n",
        "    []            # T5 (neither A nor B)\n",
        "]\n",
        "transactions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II7ZoN-bl-0M"
      },
      "source": [
        "# Q1- Perform Apirioi algorithm to get the frequent itemsets given min support = 3 and min conf 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sCbzC1vvpLUY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequent Itemsets:\n",
            "   support itemsets\n",
            "0      0.6      (A)\n",
            "1      0.6      (B)\n",
            "\n",
            "Association Rules:\n",
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, support, confidence, lift]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# Apriori implementation using mlxtend\n",
        "\n",
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder # converts a list of transactions (list of item strings) into a binary matrix (one-hot encoding).\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_array = te.fit(transactions).transform(transactions)\n",
        "df = pd.DataFrame(te_array, columns=te.columns_)\n",
        "\n",
        "# Apriori (support as fraction)\n",
        "frequent_itemsets = apriori(\n",
        "    df,\n",
        "    min_support=0.60,   # min support count = 3/5=0.6\n",
        "    use_colnames=True\n",
        ")\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(\n",
        "    frequent_itemsets,\n",
        "    metric=\"confidence\",\n",
        "    min_threshold=0.80   #min conf 80%\n",
        ")\n",
        "\n",
        "print(\"Frequent Itemsets:\")\n",
        "print(frequent_itemsets)\n",
        "\n",
        "print(\"\\nAssociation Rules:\")\n",
        "print(rules[['antecedents','consequents','support','confidence','lift']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGvEX8CMpLn6"
      },
      "source": [
        "# Q2- Perform FP-Growth algorithm to get the frequent itemsets given min support = 3 and min conf 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GXGKYzNBpXDH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Frequent Itemsets (FP-Growth) ===\n",
            "   support itemsets\n",
            "0      0.6      (B)\n",
            "1      0.6      (A)\n",
            "\n",
            "=== Association Rules (confidence >= 0.8) ===\n",
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, support, confidence, lift]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# FP-Growth / FP-Tree using mlxtend\n",
        "\n",
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
        "\n",
        "# Transactions from the image\n",
        "# Note: T5 has O repeated in the image -> in market-basket mining we count it once per transaction.\n",
        "\n",
        "# One-hot encode transactions\n",
        "te = TransactionEncoder()\n",
        "te_array = te.fit(transactions).transform(transactions)\n",
        "df = pd.DataFrame(te_array, columns=te.columns_)\n",
        "\n",
        "# Given: min support count = 3\n",
        "# We have 5 transactions => min_support fraction = 3/5 = 0.6\n",
        "min_support = 3 / len(transactions)  # 0.6\n",
        "\n",
        "# FP-Growth to get frequent itemsets\n",
        "freq_itemsets = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
        "freq_itemsets = freq_itemsets.sort_values([\"support\", \"itemsets\"], ascending=[False, True]).reset_index(drop=True)\n",
        "\n",
        "print(\"=== Frequent Itemsets (FP-Growth) ===\")\n",
        "print(freq_itemsets)\n",
        "\n",
        "#  generate association rules\n",
        "min_conf = 0.8  #min conf =80%\n",
        "rules = association_rules(freq_itemsets, metric=\"confidence\", min_threshold=min_conf)\n",
        "rules = rules.sort_values([\"confidence\", \"support\", \"lift\"], ascending=[False, False, False]).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n=== Association Rules (confidence >= {min_conf}) ===\")\n",
        "print(rules[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPgU0V2MpZSW"
      },
      "source": [
        "# Q3- Perform ECLAT algorithm to get the frequent itemsets given min support = 3 and min conf 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "yyoqYDGWJ0mb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1\n",
              "0     A     B\n",
              "1     A  None\n",
              "2     B  None\n",
              "3     A     B\n",
              "4  None  None"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyECLAT import ECLAT\n",
        "df=pd.DataFrame(transactions)                #convert to panda data type\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 1456.52it/s]\n",
            "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 1066.89it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<pyECLAT.pyECLAT.ECLAT at 0x24f79e458e0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eclat_instance = ECLAT(data=df, verbose=True) #verbose=True to see the loading bar\n",
        "eclat_instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combination 1 by 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2it [00:00, 195.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combination 2 by 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00, 494.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combination 3 by 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "get_ECLAT_indexes, get_ECLAT_supports = eclat_instance.fit(min_support=0.6,\n",
        "                                                           min_combination=1,\n",
        "                                                           max_combination=3,\n",
        "                                                           separator=' & ',\n",
        "                                                           verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'B': 0.6, 'A': 0.6}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_ECLAT_supports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SogoOxZPrArt"
      },
      "source": [
        "# Q4- Perform Apirioi algorithm to get the frequent itemsets given min support = 3 and min conf 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wgg2kOA69xP4"
      },
      "outputs": [],
      "source": [
        "#repeated as Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9o7xQ_vF2yr"
      },
      "source": [
        "# Q5- Returns a dict with:\n",
        "      - counts\n",
        "      - support\n",
        "      - confidence (X->Y, Y->X)\n",
        "      - lift (X->Y)\n",
        "      - interest (same as lift via alternative formula)\n",
        "      - contingency table counts (a,b,c,d)\n",
        "      - h-confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jA4d-wRGFpBM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "counts : {'X': 3, 'Y': 3, 'X_and_Y': 2}\n",
            "support : {'X': 0.6, 'Y': 0.6, 'X_and_Y': 0.4}\n",
            "confidence : {'X->Y': 0.6666666666666667, 'Y->X': 0.6666666666666667}\n",
            "lift (X->Y) : 1.1111111111111112\n",
            "interest : 1.1111111111111114\n",
            "contingency_table : {'a (X,Y)': 2, 'b (X,¬Y)': 1, 'c (¬X,Y)': 1, 'd (¬X,¬Y)': 1}\n",
            "h-confidence : 0.6666666666666667\n"
          ]
        }
      ],
      "source": [
        "def association_metrics(transactions, X, Y):\n",
        "    n = len(transactions)\n",
        "\n",
        "    # Contingency table counts\n",
        "    a = b = c = d = 0\n",
        "    for t in transactions:\n",
        "        t = set(t)\n",
        "        if X in t and Y in t:\n",
        "            a += 1\n",
        "        elif X in t and Y not in t:\n",
        "            b += 1\n",
        "        elif X not in t and Y in t:\n",
        "            c += 1\n",
        "        else:\n",
        "            d += 1\n",
        "\n",
        "    # Counts\n",
        "    count_X = a + b\n",
        "    count_Y = a + c\n",
        "    count_XY = a\n",
        "\n",
        "    # Supports\n",
        "    support_X = count_X / n\n",
        "    support_Y = count_Y / n\n",
        "    support_XY = count_XY / n\n",
        "\n",
        "    # Confidence\n",
        "    conf_X_to_Y = support_XY / support_X if support_X != 0 else 0\n",
        "    conf_Y_to_X = support_XY / support_Y if support_Y != 0 else 0\n",
        "\n",
        "    # Lift\n",
        "    lift_XY = support_XY / (support_X * support_Y) if support_X * support_Y != 0 else 0\n",
        "\n",
        "    # Interest (alternative lift formula)\n",
        "    interest = conf_X_to_Y / support_Y if support_Y != 0 else 0\n",
        "\n",
        "    # h-confidence\n",
        "    h_confidence = min(conf_X_to_Y, conf_Y_to_X)\n",
        "\n",
        "    return {\n",
        "        \"counts\": {\n",
        "            \"X\": count_X,\n",
        "            \"Y\": count_Y,\n",
        "            \"X_and_Y\": count_XY\n",
        "        },\n",
        "        \"support\": {\n",
        "            \"X\": support_X,\n",
        "            \"Y\": support_Y,\n",
        "            \"X_and_Y\": support_XY\n",
        "        },\n",
        "        \"confidence\": {\n",
        "            \"X->Y\": conf_X_to_Y,\n",
        "            \"Y->X\": conf_Y_to_X\n",
        "        },\n",
        "        \"lift (X->Y)\": lift_XY,\n",
        "        \"interest\": interest,\n",
        "        \"contingency_table\": {\n",
        "            \"a (X,Y)\": a,\n",
        "            \"b (X,¬Y)\": b,\n",
        "            \"c (¬X,Y)\": c,\n",
        "            \"d (¬X,¬Y)\": d\n",
        "        },\n",
        "        \"h-confidence\": h_confidence\n",
        "    }\n",
        "\n",
        "result = association_metrics(transactions, 'A', 'B')\n",
        "\n",
        "for k, v in result.items():\n",
        "    print(k, \":\", v)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Measures ===\n",
            "                   N: 5\n",
            "             count_X: 3\n",
            "             count_Y: 3\n",
            "            count_XY: 2\n",
            "           support_X: 0.6000\n",
            "           support_Y: 0.6000\n",
            "          support_XY: 0.4000\n",
            "           conf_X->Y: 0.6667\n",
            "           conf_Y->X: 0.6667\n",
            "           lift_X->Y: 1.1111\n",
            "       interest_X->Y: 1.1111\n",
            "  contingency_a(X∧Y): 2\n",
            " contingency_b(X∧¬Y): 1\n",
            " contingency_c(¬X∧Y): 1\n",
            "contingency_d(¬X∧¬Y): 1\n",
            "         h_conf(X,Y): 0.6667\n",
            "\n",
            "=== Contingency Table ===\n",
            "       B  ¬B  Total\n",
            "A      2   1      3\n",
            "¬A     1   1      2\n",
            "Total  3   2      5\n"
          ]
        }
      ],
      "source": [
        "def measures_from_transactions(transactions, X, Y):\n",
        "    \"\"\"\n",
        "    transactions: list of sets, e.g. [{\"Bread\",\"Butter\"}, {\"Bread\"}, ...]\n",
        "    X, Y: item names (strings)\n",
        "    Returns a dict with:\n",
        "      - counts\n",
        "      - support\n",
        "      - confidence (X->Y, Y->X)\n",
        "      - lift (X->Y)\n",
        "      - interest (same as lift via alternative formula)\n",
        "      - contingency table counts (a,b,c,d)\n",
        "      - h-confidence\n",
        "    \"\"\"\n",
        "    N = len(transactions)\n",
        "\n",
        "    def has(item, t):\n",
        "        return item in t\n",
        "\n",
        "    # count frequencies\n",
        "    nX  = sum(has(X, t) for t in transactions)\n",
        "    nY  = sum(has(Y, t) for t in transactions)\n",
        "    nXY = sum(has(X, t) and has(Y, t) for t in transactions)\n",
        "\n",
        "    # Contingency table:\n",
        "    '''\n",
        "     a c\n",
        "     b d\n",
        "    '''\n",
        "    # a = #(X and Y)\n",
        "    # b = #(X and not Y)\n",
        "    # c = #(not X and Y)\n",
        "    # d = #(not X and not Y)\n",
        "    a = nXY\n",
        "    b = nX - nXY\n",
        "    c = nY - nXY\n",
        "    d = N - (a + b + c)\n",
        "\n",
        "    # Supports\n",
        "    suppX  = nX / N\n",
        "    suppY  = nY / N\n",
        "    suppXY = nXY / N\n",
        "\n",
        "    # Confidence\n",
        "    conf_XY = (suppXY / suppX) if suppX > 0 else 0.0 # X -> Y\n",
        "    conf_YX = (suppXY / suppY) if suppY > 0 else 0.0 # Y -> X\n",
        "\n",
        "    # Lift / Interest\n",
        "    lift_XY = (conf_XY / suppY) if suppY > 0 else 0.0\n",
        "    interest_XY = (suppXY / (suppX * suppY)) if (suppX > 0 and suppY > 0) else 0.0\n",
        "\n",
        "    # H-confidence\n",
        "    h_conf = min(conf_XY, conf_YX)\n",
        "\n",
        "    return {\n",
        "        \"N\": N,\n",
        "        \"count_X\": nX,\n",
        "        \"count_Y\": nY,\n",
        "        \"count_XY\": nXY,\n",
        "        \"support_X\": suppX,\n",
        "        \"support_Y\": suppY,\n",
        "        \"support_XY\": suppXY,\n",
        "        \"conf_X->Y\": conf_XY,\n",
        "        \"conf_Y->X\": conf_YX,\n",
        "        \"lift_X->Y\": lift_XY,\n",
        "        \"interest_X->Y\": interest_XY,\n",
        "        \"contingency_a(X∧Y)\": a,\n",
        "        \"contingency_b(X∧¬Y)\": b,\n",
        "        \"contingency_c(¬X∧Y)\": c,\n",
        "        \"contingency_d(¬X∧¬Y)\": d,\n",
        "        \"h_conf(X,Y)\": h_conf,\n",
        "    }\n",
        "\n",
        "\n",
        "def print_contingency_table(result, X, Y):\n",
        "    a = result[\"contingency_a(X∧Y)\"]\n",
        "    b = result[\"contingency_b(X∧¬Y)\"]\n",
        "    c = result[\"contingency_c(¬X∧Y)\"]\n",
        "    d = result[\"contingency_d(¬X∧¬Y)\"]\n",
        "    N = result[\"N\"]\n",
        "\n",
        "    table = pd.DataFrame(\n",
        "        [[a, b, a + b],\n",
        "         [c, d, c + d],\n",
        "         [a + c, b + d, N]],\n",
        "        index=[X, f\"¬{X}\", \"Total\"],\n",
        "        columns=[Y, f\"¬{Y}\", \"Total\"]\n",
        "    )\n",
        "    return table\n",
        "\n",
        "\n",
        "\n",
        "X, Y = 'A', 'B'\n",
        "\n",
        "res = measures_from_transactions(transactions, X, Y)\n",
        "\n",
        "\n",
        "print(\"=== Measures ===\")\n",
        "for k, v in res.items():\n",
        "    if isinstance(v, float):\n",
        "        print(f\"{k:>20}: {v:.4f}\")\n",
        "    else:\n",
        "        print(f\"{k:>20}: {v}\")\n",
        "\n",
        "print(\"\\n=== Contingency Table ===\")\n",
        "print(print_contingency_table(res, X, Y))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
